{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598482398540",
   "display_name": "Python 3.7.6 64-bit ('unit5env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Only imports I will need\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/train.npy\")\n",
    "x_test = np.load(\"data/test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/id_index.txt\",\"r\")\n",
    "id_index = eval(f.read())\n",
    "f.close()\n",
    "f = open(\"data/index_id.txt\",\"r\")\n",
    "index_id = eval(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_train[:3]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Net:\n",
    "    def __init__(self):\n",
    "\n",
    "        # self.lr = 0.000001\n",
    "        self.lr = 0.1\n",
    "\n",
    "        # Input layer size\n",
    "        self.Input = 2540\n",
    "\n",
    "        # 2 Encoder hidden layers\n",
    "        self.Dense1 = 1024\n",
    "        self.Dense2 = 1024\n",
    "\n",
    "        # Dimentions of the latent space \n",
    "        self.Latent = 32\n",
    "\n",
    "        # 2 Decoder hidden layers\n",
    "        self.Dense3 = 1024\n",
    "        self.Dense4 = 1024\n",
    "        \n",
    "        # Output same as input\n",
    "        self.Output = 2540\n",
    "\n",
    "        # Weights\n",
    "        np.random.seed(73)\n",
    "        self.weights = {}\n",
    "\n",
    "        self.weights[\"i_d1\"] = np.random.randn(self.Input, self.Dense1) \n",
    "        self.weights['b_d1'] = np.random.randn(self.Dense1,)\n",
    "\n",
    "        self.weights[\"d1_d2\"] = np.random.randn(self.Dense1, self.Dense2) \n",
    "        self.weights['b_d2'] = np.random.randn(self.Dense2,)\n",
    "\n",
    "        self.weights[\"d2_late\"] = np.random.randn(self.Dense2, self.Latent) \n",
    "        self.weights['b_late'] = np.random.randn(self.Latent,)\n",
    "\n",
    "        self.weights[\"late_d3\"] = np.random.randn(self.Latent, self.Dense3) \n",
    "        self.weights['b_d3'] = np.random.randn(self.Dense3,)\n",
    "\n",
    "        self.weights[\"d3_d4\"] = np.random.randn(self.Dense3, self.Dense4) \n",
    "        self.weights['b_d4'] = np.random.randn(self.Dense4,)\n",
    "\n",
    "        self.weights[\"d4_out\"] = np.random.randn(self.Dense4, self.Output) \n",
    "        self.weights['b_out'] = np.random.randn(self.Output,)\n",
    "    \n",
    "    def relu(self,x):\n",
    "        return np.maximum(0,x)\n",
    "\n",
    "    def relu_gradient(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def sigmoid_gradient(self,x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "    def feedforward(self,x):\n",
    "        # Encoder\n",
    "        z_d1 = (np.dot(x, self.weights[\"i_d1\"])) + self.weights[\"b_d1\"]\n",
    "        a_d1 = self.sigmoid(z_d1)\n",
    "\n",
    "        z_d2 = (np.dot(a_d1, self.weights[\"d1_d2\"])) + self.weights[\"b_d2\"]\n",
    "        a_d2 = self.sigmoid(z_d2)\n",
    "\n",
    "        # Latent Space\n",
    "        z_late = (np.dot(a_d2, self.weights[\"d2_late\"])) + self.weights[\"b_late\"]\n",
    "        a_late = self.sigmoid(z_late)\n",
    "\n",
    "        # Decoder\n",
    "        z_d3 = (np.dot(a_late, self.weights[\"late_d3\"])) + self.weights[\"b_d3\"]\n",
    "        a_d3 = self.sigmoid(z_d3)\n",
    "\n",
    "        z_d4 = (np.dot(a_d3, self.weights[\"d3_d4\"])) + self.weights[\"b_d4\"]\n",
    "        a_d4 = self.sigmoid(z_d4)\n",
    "\n",
    "        z_out = (np.dot(a_d4, self.weights[\"d4_out\"])) + self.weights[\"b_out\"]\n",
    "        a_out = self.relu(z_out)\n",
    "        output = a_out\n",
    "\n",
    "        self.layer_outputs = {}\n",
    "        self.layer_outputs[\"z_d1\"] = z_d1\n",
    "        self.layer_outputs[\"a_d1\"] = a_d1\n",
    "        self.layer_outputs[\"z_d2\"] = z_d2\n",
    "        self.layer_outputs[\"a_d2\"] = a_d2\n",
    "        self.layer_outputs[\"z_late\"] = z_late\n",
    "        self.layer_outputs[\"a_late\"] = a_late\n",
    "        self.layer_outputs[\"z_d3\"] = z_d3\n",
    "        self.layer_outputs[\"a_d3\"] = a_d3\n",
    "        self.layer_outputs[\"z_d4\"] = z_d4\n",
    "        self.layer_outputs[\"a_d4\"] = a_d4\n",
    "        self.layer_outputs[\"z_out\"] = z_out\n",
    "        self.layer_outputs[\"a_out\"] = a_out\n",
    "        return output\n",
    "\n",
    "    def predict(self,x):\n",
    "        output = self.feedforward(x)\n",
    "        return output\n",
    "\n",
    "    def get_loss(self, output, x):\n",
    "        return np.sum(((x - output)**2) * 0.5)\n",
    "\n",
    "    def get_loss_gradient(self, output, x):\n",
    "        return (x - output)\n",
    "\n",
    "    def back_prop(self, output, x):\n",
    "        # Take the dx of the loss function\n",
    "        dx_dloss = self.get_loss_gradient(output, x)\n",
    "\n",
    "        dx_da_out = self.relu_gradient(output)\n",
    "        dx_dz_out = dx_dloss * dx_da_out\n",
    "        dx_dw_d4_out = np.dot(self.layer_outputs['a_d4'].T, dx_dz_out)\n",
    "        dx_dw_b_out = np.sum(dx_dz_out, axis=0)\n",
    "\n",
    "        dx_da_d4 = np.dot(dx_dz_out, self.weights[\"d4_out\"].T)\n",
    "        dx_dz_d4 = dx_da_d4 * self.sigmoid_gradient(self.layer_outputs[\"z_d4\"])\n",
    "        dx_dw_d3_d4 = self.layer_outputs[\"z_d3\"].T.dot(dx_dz_d4)\n",
    "        dx_dw_b_d4 = np.sum(dx_dz_d4, axis=0)\n",
    "\n",
    "        dx_da_d3 = np.dot(dx_dz_d4, self.weights[\"d3_d4\"].T)\n",
    "        dx_dz_d3 = dx_da_d3 * self.sigmoid_gradient(self.layer_outputs[\"z_d3\"])\n",
    "        dx_dw_late_d3 = self.layer_outputs[\"z_late\"].T.dot(dx_dz_d3)\n",
    "        dx_dw_b_d3 = np.sum(dx_dz_d3, axis=0)\n",
    "\n",
    "        dx_da_late = np.dot(dx_dz_d3, self.weights[\"late_d3\"].T)\n",
    "        dx_dz_late = dx_da_late * self.sigmoid_gradient(self.layer_outputs[\"z_late\"])\n",
    "        dx_dw_d2_late = self.layer_outputs[\"z_d2\"].T.dot(dx_dz_late)\n",
    "        dx_dw_b_late = np.sum(dx_dz_late, axis=0)\n",
    "\n",
    "        dx_da_d2 = np.dot(dx_dz_late, self.weights[\"d2_late\"].T)\n",
    "        dx_dz_d2 = dx_da_d2 * self.sigmoid_gradient(self.layer_outputs[\"z_d2\"])\n",
    "        dx_dw_d1_d2 = self.layer_outputs[\"z_d1\"].T.dot(dx_dz_d2)\n",
    "        dx_dw_b_d2 = np.sum(dx_dz_d2, axis=0)\n",
    "\n",
    "        dx_da_d1 = np.dot(dx_dz_d2, self.weights[\"d1_d2\"].T)\n",
    "        dx_dz_d1 = dx_da_d1 * self.sigmoid_gradient(self.layer_outputs[\"z_d1\"])\n",
    "        dx_dw_i_d1 = x.T.dot(dx_dz_d1)\n",
    "        dx_dw_b_d1 = np.sum(dx_dz_d1, axis=0)\n",
    "\n",
    "\n",
    "        # Update the weights\n",
    "        self.weights[\"i_d1\"] += self.lr * dx_dw_i_d1\n",
    "        self.weights['b_d1'] += self.lr * dx_dw_b_d1\n",
    "\n",
    "        self.weights[\"d1_d2\"] += self.lr * dx_dw_d1_d2\n",
    "        self.weights['b_d2'] += self.lr * dx_dw_b_d2\n",
    "\n",
    "        self.weights[\"d2_late\"] += self.lr * dx_dw_d2_late\n",
    "        self.weights['b_late'] += self.lr * dx_dw_b_late\n",
    "\n",
    "        self.weights[\"late_d3\"] += self.lr * dx_dw_late_d3\n",
    "        self.weights['b_d3'] += self.lr * dx_dw_b_d3\n",
    "\n",
    "        self.weights[\"d3_d4\"] += self.lr * dx_dw_d3_d4\n",
    "        self.weights['b_d4'] += self.lr * dx_dw_b_d4\n",
    "\n",
    "        self.weights[\"d4_out\"] += self.lr * dx_dw_d4_out\n",
    "        self.weights['b_out'] += self.lr * dx_dw_b_out\n",
    "\n",
    "    def train(self, x, epochs=5, batchsize=1024):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = []\n",
    "            for batch in range(round(len(x)/batchsize)):\n",
    "                minibatch = x[batch*batchsize:(batch+1)*batchsize]\n",
    "                output = self.feedforward(minibatch)\n",
    "                self.back_prop(output, minibatch)\n",
    "                loss = self.get_loss(output, minibatch)\n",
    "                total_loss.append(loss)\n",
    "                self.lr *= 0.9925\n",
    "                print(f\"Epoch {epoch+1}: Batch {batch+1} out of {round(len(x)/batchsize)}: Loss = {loss:.2f}\")\n",
    "            total_loss = np.array(total_loss)\n",
    "            print(f\"Epoch {epoch+1} of {epochs}: Loss = {np.mean(total_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feeddata(x):\n",
    "#     sigmoid = 1/(1+np.exp(-x))\n",
    "#     return np.where(sigmoid == 0.5, 0, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain = Neural_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeddata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = Brain.predict(test)\n",
    "print(pred.shape)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Brain.train(x_train, epochs=5, batchsize=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = Brain.predict(test)\n",
    "print(pred.shape)\n",
    "print(pred)\n",
    "\n",
    "# print(test[0][50:100])\n",
    "# print(pred[0][0:1000])\n",
    "# print(pred[0][1000:2000])\n",
    "# print(pred[0][2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the top row (1st user) and add an index to their values\n",
    "pred_index = np.insert(np.atleast_2d(pred[1]), 0, [num for num in range(np.atleast_2d(pred[1]).shape[1])], axis=0).T\n",
    "pred_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Return the top n scores\n",
    "top_n = 5\n",
    "top_n_pred = pred_index[pred_index[:,1].argsort()][-top_n:]\n",
    "# top_n_pred.reverse()\n",
    "print(top_n_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert top n scores to list and replace using dictionary keys\n",
    "top_n_output = [index_id[num] for num in top_n_pred[:,0]]\n",
    "print(top_n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2571,\"Matrix, The (1999)\",Action|Sci-Fi|Thriller\n",
    "# 593,\"Silence of the Lambs, The (1991)\",Crime|Horror|Thriller\n",
    "# 356,Forrest Gump (1994),Comedy|Drama|Romance|War\n",
    "# 296,Pulp Fiction (1994),Comedy|Crime|Drama|Thriller\n",
    "# 318,\"Shawshank Redemption, The (1994)\",Crime|Drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}