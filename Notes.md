# NN Notes

## Improvements I can make

- [] Implement Pymera
- [] VAE
- [] Vamp Priors
- [] Actor-Critic
- [] Top-N results

Hyperparameter (Number of hidden Layers)

Hyperparameter (Layer Sizes)

Hyperparameter (Activation Functions)

Hyperparameter (Optimization Functions)

Hyperparameter (Normalize inputs?)

# Data Cleaning Notes
csr-sparce matrix is more memory efficent

Hyperparameter (min user activity)

Hyperparameter (min item activity)

Hyperparameter (Implicit or Explicit Ratings?)

# Pymera library

## Activation Functions
Sigmoid

Hardtanh (pytorch)

Tanh

## Layers

Linear (in keras this is dense)

Dropout

NonLinear (sota)

## Other

Normalize (nn.functional)
